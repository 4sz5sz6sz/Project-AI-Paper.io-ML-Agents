{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paperio_title"
   },
   "source": [
    "# 🎮 Paper.io ML-Agents Colab Training\n",
    "\n",
    "Unity ML-Agents Paper.io 프로젝트를 Google Colab에서 학습 가능하도록 Python으로 재구현한 환경입니다.\n",
    "\n",
    "## 🌟 주요 특징\n",
    "- **정확한 Unity 복제**: MyAgent.cs의 84차원 관찰 시스템과 보상 구조를 정확히 재현\n",
    "- **4플레이어 경쟁**: 100x100 맵에서 실시간 대전\n",
    "- **PPO 학습**: ML-Agents와 동일한 하이퍼파라미터 사용\n",
    "- **실시간 시각화**: 게임 상태와 학습 진행 상황 모니터링\n",
    "- **Colab 최적화**: GPU 가속 및 TensorBoard 연동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## 📦 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# 저장소 클론\n",
    "!git clone https://github.com/4sz5sz6sz/Project-AI-Paper.io-ML-Agents.git\n",
    "%cd Project-AI-Paper.io-ML-Agents/colab_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# 의존성 설치\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_section"
   },
   "source": [
    "## 🎯 2. 빠른 데모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_demo"
   },
   "outputs": [],
   "source": [
    "# 전체 데모 실행\n",
    "!python demo_colab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## 🧠 3. 본격 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "# 학습 시작 (100K 스텝)\n",
    "!python train_colab.py --steps 100000 --tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "# TensorBoard 시작\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_section"
   },
   "source": [
    "## 🎮 4. 대화형 환경 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_env"
   },
   "outputs": [],
   "source": [
    "from paper_io_env import PaperIOEnv\n",
    "from visualizer import PaperIOVisualizer\n",
    "import numpy as np\n",
    "\n",
    "# 환경 생성\n",
    "env = PaperIOEnv()\n",
    "visualizer = PaperIOVisualizer(env)\n",
    "\n",
    "# 게임 리셋\n",
    "obs = env.reset()\n",
    "print(f\"환경 초기화 완료: {len(obs[0])} 플레이어\")\n",
    "\n",
    "# 몇 스텝 실행\n",
    "for step in range(20):\n",
    "    actions = {pid: np.random.randint(0, 4) for pid in range(1, 5)}\n",
    "    obs, rewards, dones, infos = env.step(actions)\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print(f\"스텝 {step}: 점수 = {dict(env.scores)}\")\n",
    "\n",
    "print(\"✅ 환경 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_game"
   },
   "outputs": [],
   "source": [
    "# 게임 상태 시각화\n",
    "visualizer.render_game_state(show_observations=True, target_player=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_obs"
   },
   "outputs": [],
   "source": [
    "# 관찰값 상세 분석\n",
    "visualizer.analyze_observations(player_id=1, display_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced_section"
   },
   "source": [
    "## 🔧 5. 고급 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_training"
   },
   "outputs": [],
   "source": [
    "from train_colab import PaperIOTrainer\n",
    "\n",
    "# 커스텀 설정으로 학습\n",
    "trainer = PaperIOTrainer(config_path=\"config.yaml\", use_tensorboard=True)\n",
    "\n",
    "# 하이퍼파라미터 조정\n",
    "trainer.config.update({\n",
    "    'batch_size': 4096,\n",
    "    'learning_rate': 1e-4,\n",
    "    'hidden_units': 1024\n",
    "})\n",
    "\n",
    "print(f\"설정 완료: {trainer.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "long_training"
   },
   "outputs": [],
   "source": [
    "# 장기 학습 (500K 스텝)\n",
    "trainer.train(\n",
    "    total_steps=500000,\n",
    "    save_interval=50000,\n",
    "    log_interval=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_section"
   },
   "source": [
    "## 📊 6. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "# 훈련된 모델 평가\n",
    "trainer.load_models(\"final_model\")\n",
    "eval_results = trainer.evaluate(num_episodes=20)\n",
    "\n",
    "# 결과 출력\n",
    "for player_id, metrics in eval_results.items():\n",
    "    win_rate = metrics['wins'] / 20 * 100\n",
    "    avg_score = np.mean(metrics['scores'])\n",
    "    print(f\"플레이어 {player_id}: 승률 {win_rate:.1f}%, 평균 점수 {avg_score:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_dashboard"
   },
   "outputs": [],
   "source": [
    "# 학습 진행 대시보드\n",
    "visualizer.create_training_dashboard(trainer.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": [
    "## 💾 7. 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "# 훈련된 모델 압축 및 다운로드\n",
    "!zip -r trained_models.zip models/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('trained_models.zip')\n",
    "\n",
    "print(\"모델 다운로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips_section"
   },
   "source": [
    "## 💡 팁 & 문제해결\n",
    "\n",
    "### 🚀 성능 최적화\n",
    "- GPU 런타임 사용: 런타임 > 런타임 유형 변경 > GPU\n",
    "- 배치 크기 조정: 메모리에 맞게 `batch_size` 조정\n",
    "- 병렬 환경: `num_envs` 설정으로 다중 환경 실행\n",
    "\n",
    "### 🎯 학습 안정성\n",
    "- 학습률 조정: 너무 높으면 불안정, 너무 낮으면 느림\n",
    "- 에피소드 길이: `time_horizon` 설정으로 조정\n",
    "- 정규화: `normalize: true`로 관찰값 정규화\n",
    "\n",
    "### 🔧 문제 해결\n",
    "- 메모리 부족: 배치 크기와 버퍼 크기 줄이기\n",
    "- 학습 속도: GPU 사용 확인, 네트워크 크기 조정\n",
    "- 시각화 오류: `matplotlib.use('Agg')` 백엔드 사용\n",
    "\n",
    "### 📚 추가 리소스\n",
    "- [ML-Agents 문서](https://github.com/Unity-Technologies/ml-agents)\n",
    "- [PPO 알고리즘](https://arxiv.org/abs/1707.06347)\n",
    "- [원본 Unity 프로젝트](https://github.com/4sz5sz6sz/Project-AI-Paper.io-ML-Agents)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}